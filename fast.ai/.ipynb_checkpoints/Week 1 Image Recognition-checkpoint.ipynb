{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Week 1: Image Recognition\n",
    "\n",
    "In this notebook we'll be exploring a the image classification task using convolution neural networks.  We'll be building solutions using both pre-trained models and building our own. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import tensorflow as tf\n",
    "from tensorflow import ConfigProto as config\n",
    "\n",
    "# Import our class, and instantiate\n",
    "from keras.preprocessing import image\n",
    "from keras.optimizers import rmsprop\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense, GlobalAveragePooling2D\n",
    "from keras import backend as K\n",
    "\n",
    "from keras.applications.vgg19 import VGG19"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# As large as you can, but no larger than 64 is recommended. \n",
    "# If you have an older or cheaper GPU, you'll run out of memory, so will have to decrease this.\n",
    "batch_size=64\n",
    "\n",
    "# path = \"D://Kaggle Data//dogs cats//\"\n",
    "path = \"D://Kaggle Data//dogs cats//sample//\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 200 images belonging to 2 classes.\n",
      "Found 48 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Using a class called ImageDataGenerator both as a utility for loading in raw images, but also to do \n",
    "some of the necessary data augmentation to boost generalizability.  The options are documented here:\n",
    "https://keras.io/preprocessing/image/\n",
    "\"\"\"\n",
    "\n",
    "train_datagen = image.ImageDataGenerator()\n",
    "validation_datagen = image.ImageDataGenerator()\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "                path+'train',\n",
    "                target_size=(150, 150),\n",
    "                batch_size=batch_size,\n",
    "                class_mode='binary')\n",
    "\n",
    "validation_generator = validation_datagen.flow_from_directory(\n",
    "                path+'valid',\n",
    "                target_size=(150, 150),\n",
    "                batch_size=batch_size,\n",
    "                class_mode='binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "config().gpu_options.per_process_gpu_memory_fraction = 0.4\n",
    "session = tf.Session(config=config())\n",
    "K.set_session(session)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    }
   ],
   "source": [
    "base_model = VGG19(weights='imagenet', include_top=False, classes=2)\n",
    "\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dense(1024, activation='relu')(x)\n",
    "prediction = Dense(1, activation='softmax')(x)\n",
    "\n",
    "model = Model(inputs=base_model.input, outputs=prediction)\n",
    "\n",
    "# first: train only the top layers (which were randomly initialized)\n",
    "# i.e. freeze all convolutional InceptionV3 layers\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "    \n",
    "# compile the model (should be done *after* setting layers to non-trainable)\n",
    "model.compile(optimizer='rmsprop', loss='binary_crossentropy')   \n",
    "\n",
    "# train the model on the new data for a few epochs\n",
    "model.fit_generator(\n",
    "        train_generator,\n",
    "        steps_per_epoch = 2000,\n",
    "        epochs = 10,\n",
    "        validation_data=validation_generator,\n",
    "        validation_steps=800)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
