{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting Started with Pyro\n",
    "\n",
    "Okay!  So we've gotten our feet wet with torch, and actually feel pretty good.  It was quite easy to implement a very readable version of gradient descent, which I was quite happy with. \n",
    "\n",
    "With that groundwork, lets explore pyro!  Pyro was developed by Uber for Bayesian inference, and looks like a good candidate as a next step from pymc3.\n",
    "\n",
    "As we're going through it's important to keep a few things in mind:\n",
    "\n",
    "  *  This isn't our only option. We could still transition over to Tensorflow and Edward.\n",
    "  *  We want readible models in the same way that pymc3 is very transparent about its models.  \n",
    "  *  A model in pyro shouldn't be much longer that its corresponding version in pymc3.\n",
    "\n",
    "And let's get started!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch as t # I don't see the `as t` thing in other code, but I like it\n",
    "from torch.autograd import Variable\n",
    "\n",
    "import pyro\n",
    "import pyro.distributions as dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Let create the unit normal!\n",
    "mu = Variable(t.zeros(1))\n",
    "sigma = Variable(t.ones(1))\n",
    "# dist.normal returns a sample\n",
    "X = dist.normal(mu, sigma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable containing:\n",
      " 0.9593\n",
      "[torch.FloatTensor of size 1]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Here's our sample\n",
    "print(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Variable containing:\n",
       " 1.3791\n",
       "[torch.FloatTensor of size 1]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# and it's corresponding log probability\n",
    "-dist.normal.log_pdf(X, mu, sigma)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In pyro it seems like we'll often be mroe likely to describe getting a sample in a different way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Sample with the pyro.sample function\n",
    "Y = pyro.sample(\"unit_norm\", dist.normal, mu, sigma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Variable containing:\n",
       " 1.8283\n",
       "[torch.FloatTensor of size 1]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's put this together into a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def weather():\n",
    "    \"\"\"The weather generator function\n",
    "    \n",
    "    A stochastic function which returns a sample\n",
    "    with either a cloudy or sunny classification\n",
    "    and the temperature\n",
    "    \"\"\"\n",
    "    # Cloud happens with probability 0.3\n",
    "    cloudy = pyro.sample('cloudy', dist.bernoulli,\n",
    "                         Variable(t.Tensor([0.3])))\n",
    "    \n",
    "    # If the value of the cloudy sample is 1, then cloudy\n",
    "    # I love how this is done with python control flow\n",
    "    if cloudy.data[0] == 1.0:\n",
    "        cloudy = 'cloudy'\n",
    "    else:\n",
    "        cloudy = 'sunny'\n",
    "        \n",
    "    # Once we know the weather, sample the temperature\n",
    "    # These provide our priors for cloud and sunny weather\n",
    "    # The use of dictionaries is just some nice syntax that's\n",
    "    # saving us from writing a longer if statement.\n",
    "    mean_temp = {'cloudy': [55.], 'sunny': [75.]}[cloudy]\n",
    "    sigma_temp = {'cloudy': [10.], 'sunny': [15.]}[cloudy]\n",
    "    temp = pyro.sample('temp', dist.normal,\n",
    "                       Variable(t.Tensor(mean_temp)),\n",
    "                       Variable(t.Tensor(sigma_temp)))\n",
    "    return cloudy, temp.data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('sunny', 77.79106140136719)\n",
      "('cloudy', 56.38698196411133)\n",
      "('sunny', 87.12165832519531)\n"
     ]
    }
   ],
   "source": [
    "# Drawing some samples from our generator\n",
    "for _ in range(3):\n",
    "    print(weather())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Building on an existing stochastic function is easy, since it's\n",
    "# all just python\n",
    "def go_to_the_beach():\n",
    "    cloudy, temp = weather()\n",
    "    if temp > 80.:\n",
    "        p = 0.7\n",
    "    elif temp < 80. and cloudy == 'sunny':\n",
    "        p = 0.4\n",
    "    else:\n",
    "        p = 0.05\n",
    "    \n",
    "    decision = pyro.sample('decision', dist.bernoulli,\n",
    "                           Variable(t.Tensor([p])))\n",
    "    \n",
    "    outcome = 'yes' if decision.data[0] == 1 else 'no'\n",
    "    return cloudy, temp, outcome"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('cloudy', 48.26990509033203, 'no')\n",
      "('sunny', 81.80284881591797, 'yes')\n",
      "('sunny', 75.97069549560547, 'yes')\n"
     ]
    }
   ],
   "source": [
    "for _ in range(3):\n",
    "    print(go_to_the_beach())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Delightful!  Creating different random variables and then sampling from them is quite straightforward. Maybe even easier than pymc3.\n",
    "\n",
    "So lets move on and get to some inference. \n",
    "\n",
    "Suppose we have a math assessment we give to kids (funny right), but it doesn't always give the best score representing a students ability.  To compensate we will add a 90% confidence interval based on our observations of the student. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def math_assessment(low, high):\n",
    "    # Compute the parameters of the distribution corresponding  \n",
    "    # to my CI\n",
    "    mu = Variable(t.Tensor([(low + high) / 2.]))\n",
    "    sigma = Variable(t.Tensor([(high - low) / 3.29]))\n",
    "    quantile = pyro.sample(\"quantile\", dist.normal, mu, sigma)\n",
    "    # Our CI serves as the mean for our measurement data\n",
    "    # Note that this measurement is an observed variable, but we\n",
    "    # haven't indicated that within the model quite yet.  We could\n",
    "    # do so by adding the obs argument and providing the observed\n",
    "    # \n",
    "    return pyro.sample(\"measurement\", dist.normal, quantile, Variable(t.Tensor([50.])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable containing:\n",
      " 198.5351\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Variable containing:\n",
      " 188.8906\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Variable containing:\n",
      " 184.3972\n",
      "[torch.FloatTensor of size 1]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for _ in range(3):\n",
    "    print(math_assessment(150, 250))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyro.infer import Marginal, Importance\n",
    "# This class is an importance sampler which we'll use to draw\n",
    "# from the posterior of math_assessment. It looks like we'll often\n",
    "# just pass this class into Marginal. \n",
    "posterior = Importance(math_assessment, num_samples=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable containing:\n",
      " 223.6139\n",
      "[torch.FloatTensor of size 1]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "guess = (150, 250)\n",
    "# We'll now define marginal.  Marginal acts exactly like math_assessment\n",
    "# except \n",
    "marginal = Marginal(posterior)\n",
    "print(marginal(*guess))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.text.Text at 0x19cc74293c8>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEWCAYAAABrDZDcAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x19cc672e1d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "plt.hist([marginal(150, 250).data[0] for _ in range(100)])\n",
    "plt.title(\"P(measurement | CI)\")\n",
    "plt.xlabel(\"weight\")\n",
    "plt.ylabel(\"#\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bayesian Linear Regression\n",
    "\n",
    "In the pytorch getting started we concluded with a basic demo of gradient descent for linear regression.  We'll do the same thing here, but this time for Bayesian Linear Regression.  After building the model, we'll reflect on how it compres to pymc3.\n",
    "\n",
    "We're following the guide available [on pyro's website.](http://pyro.ai/examples/bayesian_regression.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Just to make sure we have everything we need\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "from torch.autograd import Variable\n",
    "\n",
    "import pyro\n",
    "from pyro.distributions import Normal\n",
    "from pyro.infer import SVI\n",
    "from pyro.optim import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "N = 1000  # size of toy data\n",
    "p = 1    # number of features\n",
    "\n",
    "def build_linear_dataset(N, noise_std=0.1):\n",
    "    # Construct the data set in numpy\n",
    "    X = np.linspace(-5, 5, num=N)\n",
    "    y = 3 * X + 1 + np.random.normal(0, noise_std, size=N)\n",
    "    X, y = X.reshape((N, 1)), y.reshape((N, 1))\n",
    "    # Then stuff them in pytorch variables\n",
    "    X, y = Variable(torch.Tensor(X)), Variable(torch.Tensor(y))\n",
    "    return torch.cat((X, y), 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Starting with the deterministic model\n",
    "\n",
    "Curiously we start with a deterministic model and then consider distributions over its parameters. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class LinearRegression(nn.Module):\n",
    "    \"\"\"Linear Regression in pytorch\"\"\"\n",
    "    def __init__(self, p):\n",
    "        # Run nn.Module.__init__()\n",
    "        super(LinearRegression, self).__init__()\n",
    "        # Short hand for our linear module\n",
    "        self.linear = nn.Linear(p, 1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \"\"\"A typical pattern for nets is to define the forward path\"\"\"\n",
    "        # But this one's a little anti-climactic\n",
    "        return self.linear(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "regression_model = LinearRegression(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Setting up our loss function and optimizer and\n",
    "# storing them in expressive names. \n",
    "loss_fn = torch.nn.MSELoss(size_average=False)\n",
    "optim = torch.optim.Adam(regression_model.parameters(), lr=0.01)\n",
    "num_iterations = 500\n",
    "\n",
    "def main():\n",
    "    data = build_linear_dataset(N, p)\n",
    "    x_data = data[:, :-1]\n",
    "    y_data = data[:, -1]\n",
    "    for j in range(num_iterations):\n",
    "        # run the model forward on the data\n",
    "        y_pred = regression_model(x_data)\n",
    "        # calculate the mse loss\n",
    "        loss = loss_fn(y_pred, y_data)\n",
    "        # initialize gradients to zero\n",
    "        optim.zero_grad()\n",
    "        # backpropagate\n",
    "        loss.backward()\n",
    "        # take a gradient step\n",
    "        optim.step()\n",
    "        if (j + 1) % 50 == 0:\n",
    "            print(\"[iteration %04d] loss: %.4f\" % (j + 1, loss.data[0]))\n",
    "    # Inspect learned parameters\n",
    "    print(\"Learned parameters:\")\n",
    "    for name, param in regression_model.named_parameters():\n",
    "        print(\"%s: %.3f\" % (name, param.data.numpy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[iteration 0050] loss: 1016.1141\n",
      "[iteration 0100] loss: 1016.0480\n",
      "[iteration 0150] loss: 1016.0480\n",
      "[iteration 0200] loss: 1016.0479\n",
      "[iteration 0250] loss: 1016.0479\n",
      "[iteration 0300] loss: 1016.0482\n",
      "[iteration 0350] loss: 1016.0479\n",
      "[iteration 0400] loss: 1016.0482\n",
      "[iteration 0450] loss: 1016.0482\n",
      "[iteration 0500] loss: 1016.0479\n",
      "Learned parameters:\n",
      "linear.weight: 2.985\n",
      "linear.bias: 0.907\n"
     ]
    }
   ],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have a linear regression model, lets make it Bayesian"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
